ğŸ› ï¸ PROMPT: IMPLEMENT FULL .NET BACKEND WITH CRAWLER FUNCTIONALITY

You are building the backend system for a Reddit Affiliate Opportunity Engine. This backend will expose a REST API, run a custom Reddit crawler (HTML-based, not API-based), and manage all data through Supabase (PostgreSQL).

---

## ğŸ“¦ TECH STACK

- **Language:** C# (.NET 8)
- **Framework:** ASP.NET Core Web API
- **DB:** Supabase (PostgreSQL)
- **Crawler:** HTML parser with `HttpClient` + `HtmlAgilityPack`
- **Testing:** `xUnit`, `Moq`
- **ORM:** Use `Supabase.Client` SDK or direct HTTP (no EF Core)

---

## ğŸ“ PROJECT STRUCTURE TO FOLLOW

/Backend â”œâ”€â”€ Controllers/ â”œâ”€â”€ Services/ â”œâ”€â”€ Models/ â”œâ”€â”€ Repositories/ â”œâ”€â”€ Crawler/ â””â”€â”€ Tests/

yaml
Copy
Edit

---

## ğŸ§© FEATURES TO IMPLEMENT

### âœ… MODELS
Create models to match Supabase schema:
- `RedditThread`: id, title, body, subreddit, upvotes, permalink, created_utc
- `AffiliateProgram`: id, name, keywords[], promo_code, link
- `Opportunity`: thread_id, matched_keywords[], intent, score, serp_match

### âœ… REPOSITORIES
- Create repositories for each model using Supabase SDK or HTTP wrapper
- Each repo should support CRUD and search by keyword or time

### âœ… API CONTROLLERS
Implement these endpoints:
- `GET /api/opportunities` â†’ List top 25 scored opportunities
- `POST /api/keywords/match` â†’ Accept thread text and return matched programs
- `POST /api/crawler/run` â†’ Trigger manual crawl + opportunity analysis

### âœ… REDDIT HTML CRAWLER
- Scrape `hot`, `new`, `top` from selected subreddits
- Use `HtmlAgilityPack` with `HttpClient`
- Parse: title, body, permalink, upvotes, flair
- Detect duplicates before saving
- Save raw threads to `reddit_threads` via Supabase

### âœ… INTENT CLASSIFIER (RULE-BASED)
- Classify Reddit threads as:
  - DISCOVERY
  - COMPARISON
  - QUESTION
  - SHOWCASE
- Base classification on title keywords and question marks

### âœ… AFFILIATE MATCHER
- Load keyword lists from `affiliate_programs`
- Match thread text against keywords
- Return matched programs

### âœ… OPPORTUNITY ENGINE
- For each thread:
  - Classify intent
  - Run affiliate matcher
  - Run (optional) Google SERP checker stub
  - Score opportunity: based on upvotes + match strength
  - Save/update to `opportunities` table

---

## ğŸ” CRAWLER LOOP (Service)
- Accept list of subreddits from config
- Loop through each
- Fetch threads
- Process through intent + matchers
- Save results
- Log status and errors

---

## ğŸ§ª TESTING & VALIDATION
- Add `xUnit` tests for:
  - `AffiliateMatcher`
  - `IntentClassifier`
  - `RedditCrawler`
  - `OpportunityService`
- Add test runner with code coverage

---

## ğŸ§¾ CONFIG & ENV
- Use `appsettings.json` for:
  - Subreddit list
  - Supabase keys and base URL
  - Crawler delay / rate limits
- Add proper error handling for failed requests

---

## âœ… OUTPUT EXPECTATION

When finished:
- API should return structured opportunity data
- Crawler can be triggered via `/api/crawler/run`
- Database should populate with real Reddit threads
- Opportunities should include score, match list, and intent

---

âš ï¸ Do not use Reddit API â€” use HTML scraping only  
âœ… Follow .NET dependency injection best practices  
âœ… Use async methods and proper cancellation tokens  
âœ… Respect Supabase row structure (avoid schema mismatches)